{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2422f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.util import minibatch\n",
    "from spacy.training.example import Example  \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b4494b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  ...               user_timezone\n",
       "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
       "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
       "2  570301083672813571  ...  Central Time (US & Canada)\n",
       "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
       "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"Tweets.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "012b7b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0                @VirginAmerica What @dhepburn said.           neutral\n",
       "1  @VirginAmerica plus you've added commercials t...          positive\n",
       "2  @VirginAmerica I didn't today... Must mean I n...           neutral\n",
       "3  @VirginAmerica it's really aggressive to blast...          negative\n",
       "4  @VirginAmerica and it's a really big bad thing...          negative"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"text\", \"airline_sentiment\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a681e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline_sentiment\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfc340b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Neutral to a binary analysis\n",
    "\n",
    "df = df[df[\"airline_sentiment\"] != \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3bf25287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline_sentiment\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c8fd4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                 0\n",
       "airline_sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b64927d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luiz_gustavo_Andrade\\AppData\\Local\\Temp\\ipykernel_32848\\2257080823.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"airline_sentiment\"] = df[\"airline_sentiment\"].map({\"negative\":0, \"positive\":1})\n"
     ]
    }
   ],
   "source": [
    "# enconding categorical field to 0 and 1 to analysis remember computer only understands numbers\n",
    "df[\"airline_sentiment\"] = df[\"airline_sentiment\"].map({\"negative\":0, \"positive\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "99f647bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline_sentiment\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d024f6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.5/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 0.8/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 1.1 MB/s eta 0:00:11\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 1.1 MB/s eta 0:00:10\n",
      "     ------ --------------------------------- 2.1/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ------- -------------------------------- 2.4/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     -------- ------------------------------- 2.6/12.8 MB 1.3 MB/s eta 0:00:08\n",
      "     --------- ------------------------------ 2.9/12.8 MB 1.3 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 3.9/12.8 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 4.5/12.8 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 4.7/12.8 MB 1.5 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 1.5 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 1.5 MB/s eta 0:00:05\n",
      "     ------------------ --------------------- 5.8/12.8 MB 1.5 MB/s eta 0:00:05\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.5 MB/s eta 0:00:05\n",
      "     -------------------- ------------------- 6.6/12.8 MB 1.5 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 1.6 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 1.6 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 7.9/12.8 MB 1.6 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.1/12.8 MB 1.6 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 8.7/12.8 MB 1.6 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 8.9/12.8 MB 1.6 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 1.6 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.0/12.8 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.2/12.8 MB 1.7 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.7/12.8 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 11.5/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 1.7 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b04ac7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is an example test , which describes the classification\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41e626da",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd2082e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "an\n",
      "example\n",
      "test\n",
      ",\n",
      "which\n",
      "describes\n",
      "the\n",
      "classification\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f2d136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organanize ---> organanize\n",
      "organizes ---> organize\n",
      "and ---> and\n",
      "organization ---> organization\n"
     ]
    }
   ],
   "source": [
    "ex = \"organanize organizes and organization\"\n",
    "\n",
    "for token in nlp(ex):\n",
    "    print(token.text, \"--->\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "254c8a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT            | LEMMA_          | POS_     | TAG_     | DEP_        | SHAPE_   | IS_ALPHA | IS_STOP  | \n",
      "This            | this            | PRON     | DT       | nsubj       | Xxxx     |        1 |        1 | \n",
      "is              | be              | AUX      | VBZ      | ROOT        | xx       |        1 |        1 | \n",
      "an              | an              | DET      | DT       | det         | xx       |        1 |        1 | \n",
      "example         | example         | NOUN     | NN       | compound    | xxxx     |        1 |        0 | \n",
      "test            | test            | NOUN     | NN       | attr        | xxxx     |        1 |        0 | \n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 | \n",
      "which           | which           | PRON     | WDT      | nsubj       | xxxx     |        1 |        1 | \n",
      "describes       | describe        | VERB     | VBZ      | relcl       | xxxx     |        1 |        0 | \n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        1 | \n",
      "classification  | classification  | NOUN     | NN       | dobj        | xxxx     |        1 |        0 | \n"
     ]
    }
   ],
   "source": [
    "# print column headers\n",
    "\n",
    "print ('{:15} | {:15} | {:8} | {:8} | {:11} | {:8} | {:8} | {:8} | ' .format (\n",
    "    'TEXT', 'LEMMA_', 'POS_', 'TAG_', 'DEP_', 'SHAPE_', 'IS_ALPHA', 'IS_STOP'))\n",
    "\n",
    "# print various SpaCy POS attributes\n",
    "\n",
    "for token in doc: \n",
    "    print ('{:15} | {:15} | {:8} | {:8} | {:11} | {:8} | {:8} | {:8} | ' .format (\n",
    "        token.text, token.lemma_, token.pos_, token.tag_, token.dep_\n",
    "        , token.shape_, token.is_alpha, token.is_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fc7ddfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL      | ENTITY         \n",
      "PERSON     | John                                              \n",
      "GPE        | Alaska                                            \n",
      "ORG        | Starbucks                                         \n"
     ]
    }
   ],
   "source": [
    "ner_text = \"When I told John that I wanted to move to Alaska, he warned me that I'd have trouble finding a Starbucks there\"\n",
    "ner_doc = nlp(ner_text)\n",
    "\n",
    "print ('{:10} | {:15}'.format('LABEL', 'ENTITY'))\n",
    "\n",
    "for ent in ner_doc.ents[0:20]:\n",
    "    print ('{:10} | {:50}'.format(ent.label_, ent.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70b32968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When I told \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    John\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " that I wanted to move to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alaska\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", he warned me that I'd have trouble finding a \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Starbucks\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " there</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from spacy import displacy\n",
    "\n",
    "displacy.render(docs=ner_doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83509a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load spaCy model\n",
    "\n",
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6e0c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df[\"airline_sentiment\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b543e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build Text Categorizer Model\n",
    "\n",
    "config = { \n",
    "    \"threshold\": 0.5,\n",
    "  \"model\": { \n",
    "      \"@architectures\": \"spacy.TextCatEnsemble.v2\",\n",
    "      \"linear_model\": { \n",
    "          \"@architectures\": \"spacy.TextCatBOW.v2\",\n",
    "          \"exclusive_classes\": True,\n",
    "          \"ngram_size\" : 1,\n",
    "          \"no_output_layer\": False,\n",
    "      },\n",
    "      \"tok2vec\": {\n",
    "          \"@architectures\": \"spacy.Tok2Vec.v2\",\n",
    "          \"embed\": {\n",
    "              \"@architectures\": \"spacy.MultiHashEmbed.v2\",\n",
    "              \"width\": 96,\n",
    "              \"rows\": [2000, 2000, 100, 100, 100],\n",
    "               \"attrs\": [\"NORM\", \"LOWER\", \"PREFIX\", \"SUFFIX\", \"SHAPE\"],\n",
    "          },\n",
    "        \"encode\": {\n",
    "            \"@architectures\": \"spacy.MaxoutWindowEncoder.v2\",\n",
    "            \"width\": 96,\n",
    "            \"window_size\": 4,\n",
    "            \"maxout_pieces\": 3,\n",
    "            \"depth\": 4,\n",
    "        },\n",
    "      },\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "94e538db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texcat = nlp.add_pipe(\"textcat\", config=config)\n",
    "texcat.add_label(\"positive\")\n",
    "texcat.add_label(\"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f4d08c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Defining the training data \n",
    "train_data = list(zip(X_train, [{\"cats\": {\"positive\": bool(label), \"negative\": not bool(label)}} for label in y_train]))\n",
    "random.shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6500e305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 116.79460025883918\n",
      "Epoch 2, Loss: 79.84651063578116\n",
      "Epoch 3, Loss: 67.17048048218803\n",
      "Epoch 4, Loss: 53.06857063270419\n",
      "Epoch 5, Loss: 44.10873527674465\n",
      "Epoch 6, Loss: 34.13976941165087\n",
      "Epoch 7, Loss: 29.64964518223815\n",
      "Epoch 8, Loss: 25.874885351473935\n",
      "Epoch 9, Loss: 20.266115269780343\n",
      "Epoch 10, Loss: 19.29401841390989\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 5. Evaluate the model\u001b[39;00m\n\u001b[0;32m     21\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m [nlp(text)\u001b[38;5;241m.\u001b[39mcats [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m X_test]\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m(y_test, y_pred))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "# define de optmizer\n",
    "\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "for epoch in range(10):\n",
    "    losses = {}\n",
    "    random.shuffle(train_data)\n",
    "    batches = minibatch(train_data, size=8)\n",
    "    # create the minibatch\n",
    "    for batch in batches:\n",
    "        # unpack the batch\n",
    "        texts, annotations = zip(*batch)\n",
    "        # create the Example objects\n",
    "        examples = [Example.from_dict(nlp.make_doc(text), annotation) for text, annotation in zip(texts, annotations)]\n",
    "        # update the model\n",
    "        nlp.update(examples, sgd=optimizer, drop=0.2, losses=losses)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {losses['textcat']}\")\n",
    "\n",
    "# 5. Evaluate the model\n",
    "\n",
    "y_pred = [nlp(text).cats [\"positive\"] > 0.5 for text in X_test]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "77f09a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1862\n",
      "           1       0.81      0.75      0.78       447\n",
      "\n",
      "    accuracy                           0.92      2309\n",
      "   macro avg       0.87      0.85      0.86      2309\n",
      "weighted avg       0.91      0.92      0.92      2309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171ad5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
